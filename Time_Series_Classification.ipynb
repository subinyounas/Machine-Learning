{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subinyounas/tensorflow/blob/main/Time_Series_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gMgdg80M_mAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying out various time series classfication models and comparing their performance. We have chosen 3 datasets from sktime.datasets.These are:\n",
        "1) OSULeaf, ArrowHead and Gunpoint.\n",
        "Various deep learning models are used to perform classification on these univariate time series."
      ],
      "metadata": {
        "id": "8qd600KG_o4f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnT5uSnutvC1",
        "outputId": "a9a1d192-c9d4-45f3-e45c-a8edb032737d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sktime in c:\\users\\subin\\anaconda3\\lib\\site-packages (0.28.0)\n",
            "Requirement already satisfied: numpy<1.27,>=1.21 in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from sktime) (1.24.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from sktime) (23.0)\n",
            "Requirement already satisfied: pandas<2.3.0,>=1.1 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from sktime) (2.0.3)\n",
            "Requirement already satisfied: scikit-base<0.8.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from sktime) (0.7.5)\n",
            "Requirement already satisfied: scikit-learn<1.5.0,>=0.24 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from sktime) (1.3.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2 in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from sktime) (1.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from pandas<2.3.0,>=1.1->sktime) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from pandas<2.3.0,>=1.1->sktime) (2022.7)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from pandas<2.3.0,>=1.1->sktime) (2023.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from scikit-learn<1.5.0,>=0.24->sktime) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from scikit-learn<1.5.0,>=0.24->sktime) (2.2.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=1.1->sktime) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sktime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ0CTY5bxgae",
        "outputId": "db4fe483-b659-4e3e-9d8a-de93319ff086"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\subin\\anaconda3\\lib\\site-packages (2.16.1)\n",
            "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.24.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: rich in c:\\users\\subin\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\subin\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\subin\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\subin\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9fcMkuVxgae",
        "outputId": "5b04d7a6-e0f2-4169-c919-38b0aa4222e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-self-attention in c:\\users\\subin\\anaconda3\\lib\\site-packages (0.51.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\subin\\appdata\\roaming\\python\\python311\\site-packages (from keras-self-attention) (1.24.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-self-attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsP1q2UuIdwo",
        "outputId": "fee26b0d-86d4-4ece-a3fe-76ef696e64fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\subin\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n"
          ]
        }
      ],
      "source": [
        "# loading neccessary imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "import pandas as pd\n",
        "from sktime.datasets import load_UCR_UEA_dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejkNHc0eFB7w"
      },
      "outputs": [],
      "source": [
        "# method to load different datasets\n",
        "def load_data(dataset, split=\"train\", shuffle=False, return_Type=\"numpy2D\"):\n",
        "    X, y = load_UCR_UEA_dataset(name=dataset, split=split, return_type=return_Type)\n",
        "    y = keras.utils.to_categorical(y)  # convert to vector\n",
        "    permutation_train = np.random.permutation(len(X))\n",
        "    if shuffle:\n",
        "        X = X[permutation_train]\n",
        "        y = y[permutation_train]\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Process dataset - convert to tf.dataset, add shuffle , batch and prefetch\n",
        "def process_dataset(X_train, y_train, X_test, y_test, BUFFER_SIZE=200, BATCH_SIZE=32):\n",
        "\n",
        "    # convert to tensorflow datasets\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "    train_dataset = train_dataset.shuffle(len(X_train))\n",
        "    train_tf, valid_tf = keras.utils.split_dataset(\n",
        "        train_dataset, left_size=0.75, shuffle=True\n",
        "    )  # generate validation set\n",
        "    # adding shuffle, batch, and prefetch\n",
        "    train_tf_processed = train_tf.batch(BATCH_SIZE).prefetch(\n",
        "        tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "    valid_tf_processed = valid_tf.batch(BATCH_SIZE)\n",
        "    return train_tf_processed, valid_tf_processed, test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created 4 deep learning models:-\n",
        "1) CNN with 5 dense layers.\n",
        "2) RNN\n",
        "3) 1 Directional convolutional network\n",
        "4) 1D CNN with GRU"
      ],
      "metadata": {
        "id": "ylFYT_kgAe75"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrV0vU8xEH--"
      },
      "outputs": [],
      "source": [
        "# Method to generate deep learning model\n",
        "def generate_Model(nn, input_shape, no_of_classes):\n",
        "    if nn == \"fullyconnected\":\n",
        "        return keras.models.Sequential(\n",
        "            [\n",
        "                keras.layers.Input(shape=input_shape),\n",
        "                keras.layers.Dense(128, activation=\"relu\"),\n",
        "                keras.layers.Dropout(0.2),\n",
        "                keras.layers.Dense(128, activation=\"relu\"),\n",
        "                keras.layers.Dropout(0.2),\n",
        "                keras.layers.Dense(64, activation=\"relu\"),\n",
        "                keras.layers.Dropout(0.2),\n",
        "                keras.layers.Dense(32, activation=\"relu\"),\n",
        "                keras.layers.Dropout(0.2),\n",
        "                keras.layers.Flatten(),\n",
        "                keras.layers.Dense(no_of_classes, activation=\"softmax\"),\n",
        "            ],\n",
        "            name=nn,\n",
        "        )\n",
        "    if nn == \"rnn\":\n",
        "        return keras.models.Sequential(\n",
        "            [\n",
        "                keras.layers.SimpleRNN(128,input_shape = input_shape, activation=\"relu\"),\n",
        "                keras.layers.Dense(no_of_classes, activation=\"softmax\"),\n",
        "            ],\n",
        "            name=nn,\n",
        "        )\n",
        "    if nn == \"cnn\":\n",
        "        return keras.Sequential(\n",
        "            [\n",
        "                keras.layers.Input(shape=input_shape),\n",
        "                keras.layers.Conv1D(\n",
        "                    filters=64, kernel_size=3, activation=\"relu\", padding=\"same\"\n",
        "                ),\n",
        "                keras.layers.Conv1D(\n",
        "                    filters=64, kernel_size=3, activation=\"relu\", padding=\"same\"\n",
        "                ),\n",
        "                keras.layers.MaxPooling1D(pool_size=1),\n",
        "                keras.layers.Flatten(),\n",
        "                keras.layers.Dense(128, activation=\"relu\"),\n",
        "                keras.layers.Dense(no_of_classes, activation=\"softmax\"),\n",
        "            ],\n",
        "            name=nn,\n",
        "        )\n",
        "    if nn == \"gru\":\n",
        "        model = keras.Sequential(\n",
        "            [\n",
        "                keras.layers.Input(shape=input_shape),\n",
        "                keras.layers.Conv1D(\n",
        "                    filters=64, kernel_size=3, activation=\"relu\", padding=\"same\"\n",
        "                ),\n",
        "                keras.layers.MaxPooling1D(pool_size=1),\n",
        "                keras.layers.GRU(\n",
        "                    units=128, activation='tanh', return_sequences=True\n",
        "                ),\n",
        "                keras.layers.Flatten(),\n",
        "                keras.layers.Dense(units=32,activation='relu'),\n",
        "                keras.layers.Dense(units=no_of_classes, activation=\"softmax\"),\n",
        "            ],\n",
        "            name=nn,\n",
        "        )\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d0FSBwa8fTZ"
      },
      "outputs": [],
      "source": [
        "datasets = [\"GunPoint\", \"ArrowHead\" ,\"OSULeaf\"]\n",
        "models = [\n",
        "    \"gru\",\n",
        "    \"fullyconnected\",\n",
        "    \"rnn\",\n",
        "    \"cnn\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mZzb3gXC4v7"
      },
      "outputs": [],
      "source": [
        "# callbacks\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=0.00001)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                              patience=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS36gJpT8XVV",
        "outputId": "9f453a17-ef65-4541-9f07-4e5a54aae33a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.6961 - loss: 0.6122 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.5998 - loss: 0.8532 \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.4180 - loss: 1.4541\n",
            "Average accuracy for gru: 0.5827285746733347\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7261 - loss: 0.5315 \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.6220 - loss: 0.8785\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.3705 - loss: 1.4673\n",
            "Average accuracy for fullyconnected: 0.5642030835151672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\subin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - categorical_accuracy: 0.7275 - loss: 0.5149  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\subin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - categorical_accuracy: 0.6870 - loss: 0.7212  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\subin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.4697 - loss: 1.4162\n",
            "Average accuracy for rnn: 0.6429699659347534\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7463 - loss: 0.5744\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.5629 - loss: 0.9603 \n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - categorical_accuracy: 0.4633 - loss: 1.5132\n",
            "Average accuracy for cnn: 0.585606724023819\n"
          ]
        }
      ],
      "source": [
        "for model_name in models:\n",
        "    average_score = 0\n",
        "    for dataset in datasets:\n",
        "      X_train, y_train = load_data(dataset,'train',shuffle=True,return_Type=\"numpy3D\")\n",
        "      X_test , y_test = load_data(dataset,'test',return_Type=\"numpy3D\")\n",
        "      num_of_classes = y_train.shape[1] #for output layer\n",
        "      input_shape = X_train.shape[1:] #for input layer\n",
        "      train_data,valid_data,test_data = process_dataset(X_train,y_train,X_test,y_test)\n",
        "\n",
        "      model = generate_Model(model_name,input_shape,num_of_classes)\n",
        "      model.compile(\n",
        "          optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "          loss=keras.losses.CategoricalCrossentropy(),\n",
        "          metrics=[\n",
        "              keras.metrics.CategoricalAccuracy(),\n",
        "          ],\n",
        "      )\n",
        "      model.fit(train_data, epochs=50, validation_data=valid_data, callbacks=[reduce_lr, early_stopping], verbose=0)\n",
        "      result = model.evaluate(test_data.batch(32), return_dict=True)\n",
        "      average_score += result['categorical_accuracy'] / len(datasets)\n",
        "    print(f'Average accuracy for {model_name}: {average_score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison of CNN classifier from Sktime and two baseline deep learning models MLP and FCN.\n",
        " - [Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline (2017)](https://arxiv.org/abs/1611.06455) - Reference for baseline model"
      ],
      "metadata": {
        "id": "b-WaY8AiBImI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp3BTSzieK0L"
      },
      "outputs": [],
      "source": [
        "from sktime.classification.deep_learning.cnn import CNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98HqlPkHxgai"
      },
      "outputs": [],
      "source": [
        "reduce_lr_cnn = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=3, min_lr=0.00001)\n",
        "early_stopping_cnn = keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                              patience=10,mode=\"min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p9qzU50xgai",
        "outputId": "4d9e0210-46d7-43bb-95ea-ab656a86c665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Categorical score for CNN on dataset 'GunPoint' is: 0.8\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Categorical score for CNN on dataset 'ArrowHead' is: 0.5085714285714286\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Categorical score for CNN on dataset 'OSULeaf' is: 0.5\n",
            "Average score for CNN classifier is: 0.6028571428571429\n"
          ]
        }
      ],
      "source": [
        "average_score = 0\n",
        "for dataset in datasets:\n",
        "    X_train, y_train = load_UCR_UEA_dataset(\n",
        "        name=dataset, split=\"train\", return_type=\"numpy2D\"\n",
        "    )\n",
        "    X_test, y_test = load_UCR_UEA_dataset(\n",
        "        name=dataset, split=\"test\", return_type=\"numpy2D\"\n",
        "    )\n",
        "    model = CNNClassifier(\n",
        "        n_epochs=60,\n",
        "        batch_size=32,\n",
        "        callbacks=[reduce_lr_cnn, early_stopping_cnn],\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    score = model.score(X_test, y_test)\n",
        "    print(f\"Categorical score for CNN on dataset '{dataset}' is:\", score)\n",
        "    average_score += score / len(datasets)\n",
        "print(\"Average score for CNN classifier is:\", average_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRtwZXYpxgai"
      },
      "outputs": [],
      "source": [
        "def get_model(model_name, input_shape, num_of_classes):\n",
        "    if model_name == \"mlp\":\n",
        "        return keras.Sequential(\n",
        "            [\n",
        "                keras.layers.Input(shape=input_shape, name=\"Input\"),\n",
        "                keras.layers.Dropout(rate=0.1),\n",
        "                keras.layers.Dense(units=500, activation=\"relu\"),\n",
        "                keras.layers.Dropout(rate=0.2),\n",
        "                keras.layers.Dense(units=500, activation=\"relu\"),\n",
        "                keras.layers.Dropout(rate=0.2),\n",
        "                keras.layers.Dense(units=500, activation=\"relu\"),\n",
        "                keras.layers.Dropout(rate=0.3),\n",
        "                keras.layers.Flatten(),\n",
        "                keras.layers.Dense(num_of_classes, activation=\"softmax\"),\n",
        "            ],\n",
        "            name=model_name,\n",
        "        )\n",
        "    elif model_name == \"fcn\":\n",
        "        return keras.Sequential(\n",
        "            [\n",
        "                keras.layers.Input(shape=input_shape, name=\"Input\"),\n",
        "                keras.layers.Conv1D(\n",
        "                    128, activation=\"relu\", kernel_size=8, padding=\"same\"\n",
        "                ),\n",
        "                keras.layers.BatchNormalization(),\n",
        "                keras.layers.Conv1D(\n",
        "                    256, activation=\"relu\", kernel_size=5, padding=\"same\"\n",
        "                ),\n",
        "                keras.layers.BatchNormalization(),\n",
        "                keras.layers.Conv1D(\n",
        "                    128, activation=\"relu\", kernel_size=3, padding=\"same\"\n",
        "                ),\n",
        "                keras.layers.BatchNormalization(),\n",
        "                keras.layers.GlobalAveragePooling1D(),\n",
        "                keras.layers.Flatten(),\n",
        "                keras.layers.Dense(num_of_classes, activation=\"softmax\", name=\"Output\"),\n",
        "            ],\n",
        "            name=model_name,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qk2v2zaxgai"
      },
      "outputs": [],
      "source": [
        "model_list = [\"mlp\", \"fcn\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkNFheVUxgai",
        "outputId": "b1a307d9-c925-4c30-9e39-2f0c5517e5b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - categorical_accuracy: 0.7162 - loss: 1.0128\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.6506 - loss: 0.8929\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - categorical_accuracy: 0.4556 - loss: 1.5217 \n",
            "Average accuracy for mlp: 0.6142804821332296\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - categorical_accuracy: 0.6487 - loss: 0.9573  \n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.6712 - loss: 1.0224\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4158 - loss: 1.6731 \n",
            "Average accuracy for fcn: 0.521038959423701\n"
          ]
        }
      ],
      "source": [
        "for model_name in model_list:\n",
        "    average_score = 0\n",
        "    for dataset in datasets:\n",
        "        X_train, y_train = load_data(dataset, \"train\", shuffle=True,return_Type=\"numpy3D\")\n",
        "        X_test, y_test = load_data(dataset, \"test\",return_Type=\"numpy3D\")\n",
        "        num_of_classes = y_train.shape[1]  # for output layer\n",
        "        input_shape = X_train.shape[1:]  # for input layer\n",
        "        train_data, valid_data, test_data = process_dataset(\n",
        "            X_train, y_train, X_test, y_test\n",
        "        )\n",
        "        model = get_model(model_name, input_shape, num_of_classes)\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "            loss=keras.losses.CategoricalCrossentropy(),\n",
        "            metrics=[\n",
        "                keras.metrics.CategoricalAccuracy(),\n",
        "            ],\n",
        "        )\n",
        "        model.fit(\n",
        "            train_data,\n",
        "            epochs=60,\n",
        "            validation_data=valid_data,\n",
        "            callbacks=[reduce_lr, early_stopping],\n",
        "            verbose=0,\n",
        "        )\n",
        "        result = model.evaluate(test_data.batch(32), return_dict=True)\n",
        "        average_score += result[\"categorical_accuracy\"] / len(datasets)\n",
        "    print(f\"Average accuracy for {model_name}: {average_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a concatenated deep learning model by combining Bi directional lstm and 1D convulation network"
      ],
      "metadata": {
        "id": "KnDLRtxuB8hx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQDaJ4bAxgaj"
      },
      "outputs": [],
      "source": [
        "# using Bi direction LSTM and CNN on the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z00ZOCqDFZeC"
      },
      "outputs": [],
      "source": [
        "def get_bi_lstm_layer(input):\n",
        "    return Sequential(\n",
        "        [\n",
        "            keras.layers.Bidirectional(keras.layers.LSTM(200, return_sequences=True)),\n",
        "        ]\n",
        "    )(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUiRqrXOxgaj"
      },
      "outputs": [],
      "source": [
        "def get_cnn_layer(input):\n",
        "    conv_layers = Sequential(\n",
        "        [\n",
        "            keras.layers.Conv1D(200, kernel_size=8, padding=\"same\", activation=\"relu\"),\n",
        "        ]\n",
        "    )(input)\n",
        "    return conv_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNIztKmqxgaj"
      },
      "outputs": [],
      "source": [
        "def get_combined_model(input_shape, num_of_classes):\n",
        "    input = keras.layers.Input(input_shape)\n",
        "    cnn_layer = get_cnn_layer(input)\n",
        "\n",
        "    lstm_layer = get_bi_lstm_layer(input)\n",
        "\n",
        "    combined_layer = keras.layers.Concatenate()([cnn_layer, lstm_layer])\n",
        "\n",
        "    outputs = keras.layers.Conv1D(128, kernel_size=3, padding=\"same\", activation=\"relu\")(combined_layer)\n",
        "    outputs = keras.layers.GlobalMaxPooling1D()(outputs)\n",
        "    outputs = keras.layers.Dense(num_of_classes, activation='softmax')(outputs)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCY_32b9xgaj",
        "outputId": "8de7e5f1-1ca6-486c-8c07-08abb27073b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.6983 - loss: 0.4489\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.7011 - loss: 0.7166\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4901 - loss: 1.3759 \n",
            "Average accuracy for combined model: 0.6371481021245321\n"
          ]
        }
      ],
      "source": [
        "average_score = 0\n",
        "for dataset in datasets:\n",
        "    X_train, y_train = load_data(dataset, \"train\", shuffle=True,return_Type=\"numpy3D\")\n",
        "    X_test, y_test = load_data(dataset, \"test\",return_Type=\"numpy3D\")\n",
        "    num_of_classes = y_train.shape[1]  # for output layer\n",
        "    input_shape = X_train.shape[1:]  # for input layer\n",
        "    train_data, valid_data, test_data = process_dataset(\n",
        "        X_train, y_train, X_test, y_test\n",
        "    )\n",
        "\n",
        "    model = get_combined_model(input_shape, num_of_classes)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=[\n",
        "            keras.metrics.CategoricalAccuracy(),\n",
        "        ],\n",
        "    )\n",
        "    model.fit(\n",
        "        train_data,\n",
        "        epochs=60,\n",
        "        validation_data=valid_data,\n",
        "        callbacks=[reduce_lr, early_stopping],\n",
        "        verbose=0,\n",
        "    )\n",
        "    result = model.evaluate(test_data.batch(32), return_dict=True)\n",
        "    average_score += result[\"categorical_accuracy\"] / len(datasets)\n",
        "print(f\"Average accuracy for combined model: {average_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using transformers from sktime to transform the data before classifying with sktime CNN classifier"
      ],
      "metadata": {
        "id": "mZsX5V0uCVVe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bynLLOqsxgaj"
      },
      "outputs": [],
      "source": [
        "#using sktime transformer + deeplearning (CNN Classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ul6waJwbxgaj"
      },
      "outputs": [],
      "source": [
        "from sktime.transformations.series.impute import Imputer\n",
        "from sktime.transformations.series.boxcox import BoxCoxTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "differencer = Imputer(method=\"drift\")\n",
        "box_cox = BoxCoxTransformer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uba7bymxxgak"
      },
      "outputs": [],
      "source": [
        "def transform(X_train,X_test):\n",
        "    pipe = Pipeline(steps=[(\"differencer\", differencer), (\"boxcox\", box_cox)])\n",
        "\n",
        "    # transform X-train\n",
        "    X_train_transformed = pipe.fit_transform(X_train)\n",
        "    X_test_transformed = pipe.transform(X_test)\n",
        "    return X_train_transformed,X_test_transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI-i3x5pxgak",
        "outputId": "69b3fe99-951f-4bac-ef8f-9681d07a16ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001DE9A749DA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Categorical score for CNN on dataset 'GunPoint' is: 0.5466666666666666\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Categorical score for CNN on dataset 'ArrowHead' is: 0.5942857142857143\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Categorical score for CNN on dataset 'OSULeaf' is: 0.371900826446281\n",
            "Average score for CNN classifier is: 0.5042844024662206\n"
          ]
        }
      ],
      "source": [
        "average_score = 0\n",
        "for dataset in datasets:\n",
        "    X_train, y_train = load_UCR_UEA_dataset(\n",
        "        name=dataset, split=\"train\", return_type=\"numpy2D\"\n",
        "    )\n",
        "    X_test, y_test = load_UCR_UEA_dataset(\n",
        "        name=dataset, split=\"test\", return_type=\"numpy2D\"\n",
        "    )\n",
        "    X_train_transformed, X_test_transformed = transform(X_train, X_test)\n",
        "    model = CNNClassifier(\n",
        "        n_epochs=60, batch_size=32, callbacks=[reduce_lr_cnn, early_stopping_cnn]\n",
        "    )\n",
        "    model.fit(X_train_transformed, y_train)\n",
        "    score = model.score(X_test_transformed, y_test)\n",
        "    print(f\"Categorical score for CNN on dataset '{dataset}' is:\", score)\n",
        "    average_score += score / len(datasets)\n",
        "print(\"Average score for CNN classifier is:\", average_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using SklearnClassifierPipeline to combine sktime transformers and an sklearn classifier. Combined the Rocket and Exponent transformer with RandomForest classfier to make a pipeline.\n",
        "Random search to find the best model and parameters"
      ],
      "metadata": {
        "id": "FMXPEvpGC5H6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KccHsEFbFcPO"
      },
      "outputs": [],
      "source": [
        "from sktime.classification.compose import SklearnClassifierPipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sktime.transformations.panel.rocket import Rocket\n",
        "from sktime.transformations.series.exponent import ExponentTransformer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st6YTwXHxgak"
      },
      "outputs": [],
      "source": [
        "exponent = ExponentTransformer()\n",
        "rocket = Rocket()\n",
        "classifier = RandomForestClassifier()\n",
        "pipeline = SklearnClassifierPipeline(\n",
        "    classifier, transformers=[(\"exponent\", exponent), (\"rocket\", rocket)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0OcPnXIxgak"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"classifier__max_depth\": [3, 5, 7, 9],\n",
        "    \"rocket__normalise\": [True, False],\n",
        "    \"exponent__power\": [1, 2, 3, 4, 5],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7uIiKkFxgap",
        "outputId": "e074bb6c-75dd-47dd-c74f-6a9aec9cbbe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test score of the best model:0.7899894467058646\n"
          ]
        }
      ],
      "source": [
        "dataset = datasets[2]\n",
        "X_train, y_train = load_UCR_UEA_dataset(\n",
        "    name=dataset, split=\"train\", return_type=\"numpy2D\"\n",
        ")\n",
        "X_test , y_test = load_UCR_UEA_dataset(\n",
        "    name=dataset, split=\"test\", return_type=\"numpy2D\"\n",
        ")\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=3,\n",
        "    cv=3,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    error_score=\"raise\"\n",
        ")\n",
        "random_search.fit(X_train, y_train)\n",
        "print(f\"Best score:{random_search.best_score_}\") #best score form Random Search\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-UxWTze_A--",
        "outputId": "caeb5580-0aad-4a26-a83c-06ea60203759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best params:{'rocket__normalise': False, 'exponent__power': 3, 'classifier__max_depth': 5}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best params:{random_search.best_params_}\") #best params form Random Search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgRVXriK_A-_",
        "outputId": "92c6bdd9-a2be-4733-9fd1-9106ac6cb699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best estimator:SklearnClassifierPipeline(classifier=RandomForestClassifier(max_depth=5),\n",
            "                          transformers=[('exponent',\n",
            "                                         ExponentTransformer(power=3)),\n",
            "                                        ('rocket', Rocket(normalise=False))])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7396694214876033"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f\"Best estimator:{random_search.best_estimator_}\") #best estimator form Random Search\n",
        "best_estimator = random_search.best_estimator_\n",
        "best_estimator.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGacaprgxgap",
        "outputId": "aab0f472-f3b0-4054-8c40-b777c263e0c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score on default pipeline:0.8057851239669421\n"
          ]
        }
      ],
      "source": [
        "# getting the score of the default pipeline on the test set\n",
        "pipe = SklearnClassifierPipeline(\n",
        "    RandomForestClassifier(), transformers=[(\"exponent\", ExponentTransformer()), (\"rocket\", Rocket())]\n",
        ")\n",
        "pipe.fit(X_train, y_train)\n",
        "score = pipe.score(X_test, y_test)\n",
        "print(f\"Score on default pipeline:{score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time series classification of Multivariate time series. Loaded the BasicMotions time series and performed classfication using Tapnet and Rocket from sktime and with MLP deep learning model. Compared the test scores."
      ],
      "metadata": {
        "id": "czodSnFwDJCy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-KVpZFRxgap"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sktime.classification.deep_learning.tapnet import TapNetClassifier\n",
        "from sktime.classification.kernel_based import RocketClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9x_0wkPxgap"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder() #used to convert categories to int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-8_3xFkxgaq"
      },
      "outputs": [],
      "source": [
        "dataset = \"BasicMotions\"\n",
        "X_train, y_train = load_UCR_UEA_dataset(\n",
        "    name=dataset, split=\"train\", return_type=\"numpy3D\"\n",
        ")\n",
        "X_test, y_test = load_UCR_UEA_dataset(\n",
        "    name=dataset, split=\"test\", return_type=\"numpy3D\"\n",
        ")\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "y_test_encoded = le.fit_transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBaUAVXEleX6",
        "outputId": "46c3d8c6-76df-48c5-db00-a30ebde86969"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\subin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:187: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 248ms/step\n",
            "Score of tapnet classifier:1.0\n"
          ]
        }
      ],
      "source": [
        "tapnet = TapNetClassifier()\n",
        "tapnet.fit(X_train,y_train_encoded)\n",
        "tapnet_score = tapnet.score(X_test, y_test_encoded)\n",
        "print(f\"Score of tapnet classifier:{tapnet_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBcPye49lfNG",
        "outputId": "034fc2b1-1311-4997-b59d-80a0fe90b961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score of rocket classifier:1.0\n"
          ]
        }
      ],
      "source": [
        "rocket = RocketClassifier()\n",
        "rocket.fit(X_train,y_train_encoded)\n",
        "rocket_score = rocket.score(X_test, y_test_encoded)\n",
        "print(f\"Score of rocket classifier:{rocket_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRzlRE9pMxqi"
      },
      "outputs": [],
      "source": [
        "y_train_one_hot = keras.utils.to_categorical(y_train_encoded)\n",
        "y_test_one_hot = keras.utils.to_categorical(y_test_encoded)\n",
        "train_data ,valid_data,test_data = process_dataset(X_train,y_train_one_hot,X_test,y_test_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "CAVwoleGxgaq",
        "outputId": "660dd02f-a24f-4a3f-8368-6f96be113403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - categorical_accuracy: 0.5667 - loss: 1.0540\n",
            "Test score of the deep learning Model:0.6000000238418579\n"
          ]
        }
      ],
      "source": [
        "# for performing classification with deep learning model\n",
        "input_shape = X_train.shape[1:]\n",
        "num_of_classes = len(np.unique(y_train_encoded))\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Input(shape=input_shape, name=\"Input\"),\n",
        "        keras.layers.Dropout(rate=0.1),\n",
        "        keras.layers.Dense(units=500, activation=\"relu\"),\n",
        "        keras.layers.Dropout(rate=0.2),\n",
        "        keras.layers.Dense(units=500, activation=\"relu\"),\n",
        "        keras.layers.Dropout(rate=0.2),\n",
        "        keras.layers.Dense(units=500, activation=\"relu\"),\n",
        "        keras.layers.Dropout(rate=0.3),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(num_of_classes, activation=\"softmax\"),\n",
        "    ],\n",
        "    name=\"mlp\",\n",
        ")\n",
        "model.compile(\n",
        "\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\n",
        "        keras.metrics.CategoricalAccuracy(),\n",
        "    ],\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    train_data,\n",
        "    epochs=50,\n",
        "    validation_data=valid_data,\n",
        "    callbacks=[reduce_lr, early_stopping],\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "\n",
        "result = model.evaluate(test_data.batch(32), return_dict=True)\n",
        "\n",
        "\n",
        "score = result[\"categorical_accuracy\"]\n",
        "\n",
        "\n",
        "print(f\"Test score of the deep learning Model:{score}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}